{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nivedit\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\Nivedit\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict,train_test_split\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "from sklearn.preprocessing import imputation, StandardScaler, minmax_scale, LabelEncoder, Normalizer, Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get HEATMAP of Co-realtion along with values\n",
    "def fun_heatmap(corr): # corr is the object for holding 'corelation' matrix\n",
    "    plt.figure(figsize=(14,10))\n",
    "    sns.heatmap(corr, vmax=1, square=True, annot=True, \n",
    "                xticklabels=corr.columns.values, \n",
    "                yticklabels=corr.columns.values, cmap = 'cubehelix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funtion to open, read and convert its components into integer as a list\n",
    "def read_csv(csv_file):  # csv_file to hold CSV format file\n",
    "    f = open(csv_file, \"r\")  # open this file into read format\n",
    "    \n",
    "    text = f.read()   # read this file into text as string\n",
    "    \n",
    "    string_list = text.split(\"\\n\")   # to split this text basis new line i.e. \"\\n\" \n",
    "    \n",
    "    new_string_list = string_list[1:]    # Since first row can be header, thus to avoid 1st row\n",
    "    \n",
    "    final_list = []\n",
    "    \n",
    "    for i in new_string_list:\n",
    "        another_list = i.split(\",\")\n",
    "        \n",
    "        int_list = []\n",
    "        \n",
    "        for j in another_list:\n",
    "            int_list.append(int(j))\n",
    "        \n",
    "        final_list.append(int_list)\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basis specific Index/Column in a list, calculate respective values and put them in a Dictionary\n",
    "def calc_count(input_list, index):\n",
    "    dict_to_return = {}\n",
    "    \n",
    "    for i in input_list:\n",
    "        value = i[-1]\n",
    "        keys = i[index]\n",
    "        \n",
    "        if keys in dict_to_return.keys():\n",
    "            dict_to_return[keys] = dict_to_return[keys] + value\n",
    "        else:\n",
    "            dict_to_return[keys] = value\n",
    "        \n",
    "    return dict_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to Plot Confusion Matrix\n",
    "def fun_plot_confusion_matrix(conf):\n",
    "    plt.rcParams['figure.figsize'] = 4,3\n",
    "    cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "    # add ticklabels as per classes; for 3 classes - xticklabels=['0','1','2']\n",
    "    sns.heatmap(conf,cmap = cmap,xticklabels=['0','1'],yticklabels=['0','1'],annot=True, fmt=\"d\",)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to Calculate & Print TPR / FPR / Specificity / Precision basis different Confusion-Matrix developed\n",
    "def fun_conf_mat_calc(conf):\n",
    "    conf_accuracy_score = np.round(((conf.item(0) + conf.item(3)) / conf.sum()) * 100, 2)\n",
    "    print('Overall Accuracy:', conf_accuracy_score)\n",
    "    \n",
    "    TPR = Recall = Sensitivity = np.round((conf.item(3) / (conf.item(2) + conf.item(3)))*100,2)\n",
    "    print('TPRate or Recall or Sensitivity i.e. (TP / Actual YES):', TPR)\n",
    "    \n",
    "    FPR = np.round((conf.item(1) / (conf.item(0) + conf.item(1)))*100,2)\n",
    "    print('FPRate i.e. (FP / Actual NO):', FPR)\n",
    "    \n",
    "    Specificity = np.round((conf.item(0) / (conf.item(0) + conf.item(1)))*100,2)\n",
    "    print('Specificity i.e. (TN / Actual NO):', Specificity)\n",
    "    \n",
    "    Precision = np.round((conf.item(3) / (conf.item(1) + conf.item(3)))*100,2)\n",
    "    print('Precision i.e. (TP / Predicted YES):', Precision)\n",
    "    \n",
    "    #return (zip(('TPR', 'FPR', 'Specificity', 'Precision'),(TPR, FPR, Specificity, Precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate TPR / Recall basis differet Confusion Matrix\n",
    "def fun_TPR_calc(conf):\n",
    "    TPR = Recall = Sensitivity = np.round((conf.item(3) / (conf.item(2) + conf.item(3)))*100,2)\n",
    "    return(TPR)\n",
    "\n",
    "# Function to calculate FPR\n",
    "def fun_FPR_calc(conf):\n",
    "    FPR = np.round((conf.item(1) / (conf.item(0) + conf.item(1)))*100,2)\n",
    "    return(FPR)\n",
    "\n",
    "# Function to calculate Specificity \n",
    "def fun_Spec_calc(conf):\n",
    "    Spec = np.round((conf.item(0) / (conf.item(0) + conf.item(1)))*100,2)\n",
    "    return(Spec)\n",
    "\n",
    "# Function to calculate Precision\n",
    "def fun_Prec_calc(conf):\n",
    "    Prec = np.round((conf.item(3) / (conf.item(1) + conf.item(3)))*100,2)\n",
    "    return(Prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Function for plotting Variance Ratio\n",
    "def fun_plot_variance_ratio_cumsum(variance_ratio):\n",
    "    variance_ratio_cumsum = np.cumsum(np.round(variance_ratio, decimals=4)*100)\n",
    "    print(variance_ratio_cumsum)\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = 6,4\n",
    "    plt.plot(variance_ratio_cumsum)\n",
    "    plt.title(\"Cumulative Variance\")\n",
    "    plt.xlabel(\"No. of Components\")\n",
    "    plt.ylabel(\"Variance Explained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to find correct k in knn basis range from 1 to 25\n",
    "def fun_evaluate_k_in_knn(X, Y):\n",
    "    k_range =range(1,25)\n",
    "    k_scores = []\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        scores = cross_val_score(knn, X, Y, cv = 10, scoring = 'accuracy')\n",
    "        k_scores.append(scores.mean())\n",
    "    print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funtion to get all Numeric Variables from DF\n",
    "def fun_get_numeric_variables(df):\n",
    "    numeric_variables = list(df.dtypes[df.dtypes != 'object'].index)\n",
    "    return df[numeric_variables]\n",
    "\n",
    "# Funtion to get all Non-Numeric Variables from DF\n",
    "def fun_get_non_numeric_variables(df):\n",
    "    non_numeric_variables = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "    return df[non_numeric_variables]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
